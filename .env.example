# =============================================================================
# EMAIL SCRAPER - ENVIRONMENT CONFIGURATION
# =============================================================================
# For CI/CD Deployment:
# 1. DO NOT commit .env file to GitHub (it's in .gitignore)
# 2. Set these as environment variables or secrets in your CI/CD platform
# 3. On the server, either:
#    - Set environment variables directly, OR
#    - Create .env file with actual values
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED - Must be configured for production
# -----------------------------------------------------------------------------

# Database URL (PostgreSQL recommended for production)
# CI/CD: Set as secret DATABASE_URL
DATABASE_URL=postgresql://user:password@db-host:5432/email_scraper

# Redis URL (for Celery task queue)
# CI/CD: Set as secret REDIS_URL
REDIS_URL=redis://redis-host:6379/0

# Flask Secret Key - MUST be unique random string in production!
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
# CI/CD: Set as secret SESSION_SECRET
SESSION_SECRET=generate-a-random-64-char-hex-string-here

# -----------------------------------------------------------------------------
# PRODUCTION SETTINGS
# -----------------------------------------------------------------------------

# Enable HTTPS cookies (set true when using HTTPS)
SESSION_COOKIE_SECURE=true

# URL Scheme
PREFERRED_URL_SCHEME=https

# Trust proxy headers (nginx, cloudflare, etc.)
PROXY_FIX=true

# Flask debug mode (ALWAYS false in production)
FLASK_DEBUG=false

# -----------------------------------------------------------------------------
# DATABASE POOL (for high concurrency)
# -----------------------------------------------------------------------------
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=100

# -----------------------------------------------------------------------------
# CELERY WORKERS
# -----------------------------------------------------------------------------
SCRAPE_WORKERS=4
OPS_WORKERS=2
CELERY_CONCURRENCY=10

# -----------------------------------------------------------------------------
# SCRAPER SETTINGS
# -----------------------------------------------------------------------------
PLAYWRIGHT_FALLBACK=true
SCRAPER_LOG_LEVEL=INFO
DOMAIN_RATE_LIMIT=0.5
SCRAPER_BATCH_SIZE=500
PROXY_FAIL_THRESHOLD=10

# -----------------------------------------------------------------------------
# SERVER SETTINGS
# -----------------------------------------------------------------------------
HOST=0.0.0.0
PORT=5000
SERVER=waitress
WAITRESS_THREADS=8

# =============================================================================
# CI/CD DEPLOYMENT - GITHUB SECRETS SETUP
# =============================================================================
#
# Go to: GitHub Repo → Settings → Secrets and variables → Actions → New secret
#
# REQUIRED SECRETS (add these to GitHub):
# ┌────────────────────┬─────────────────────────────────────────────────────┐
# │ Secret Name        │ Value / Description                                 │
# ├────────────────────┼─────────────────────────────────────────────────────┤
# │ EC2_HOST           │ Your EC2 public IP (e.g., 54.123.45.67)            │
# │ EC2_USER           │ ubuntu (default EC2 user)                          │
# │ EC2_SSH_KEY        │ Contents of your .pem file (full text)             │
# │ DOCKER_USERNAME    │ Your Docker Hub username                           │
# │ DOCKER_PASSWORD    │ Docker Hub access token                            │
# │ DB_PASSWORD        │ Strong password for PostgreSQL                     │
# │ SESSION_SECRET     │ Run: python -c "import secrets;print(secrets.token_hex(32))" │
# └────────────────────┴─────────────────────────────────────────────────────┘
#
# OPTIONAL SECRETS:
# ┌────────────────────┬─────────────────────────────────────────────────────┐
# │ DB_USER            │ postgres (default)                                 │
# │ DB_NAME            │ email_scraper (default)                            │
# │ DATABASE_URL       │ Only if using AWS RDS instead of Docker PostgreSQL │
# │ CELERY_CONCURRENCY │ 4 (default)                                        │
# └────────────────────┴─────────────────────────────────────────────────────┘
#
# HOW IT WORKS:
# 1. You add secrets to GitHub (they stay encrypted, never in code)
# 2. When you push to main branch, GitHub Actions runs
# 3. The workflow SSHs into your EC2 server
# 4. It creates the .env file on the server using your GitHub secrets
# 5. Docker Compose reads .env and starts all services
#
# The .env file is NEVER stored in git - it's created during deployment
# =============================================================================
