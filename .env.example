# =============================================================================
# EMAIL SCRAPER - ENVIRONMENT CONFIGURATION
# =============================================================================
# For CI/CD Deployment:
# 1. DO NOT commit .env file to GitHub (it's in .gitignore)
# 2. Set these as environment variables or secrets in your CI/CD platform
# 3. On the server, either:
#    - Set environment variables directly, OR
#    - Create .env file with actual values
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED - Must be configured for production
# -----------------------------------------------------------------------------

# Database URL (PostgreSQL recommended for production)
# CI/CD: Set as secret DATABASE_URL
DATABASE_URL=postgresql://user:password@db-host:5432/email_scraper

# Redis URL (for Celery task queue)
# CI/CD: Set as secret REDIS_URL
REDIS_URL=redis://redis-host:6379/0

# Flask Secret Key - MUST be unique random string in production!
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
# CI/CD: Set as secret SESSION_SECRET
SESSION_SECRET=generate-a-random-64-char-hex-string-here

# -----------------------------------------------------------------------------
# PRODUCTION SETTINGS
# -----------------------------------------------------------------------------

# Enable HTTPS cookies (set true when using HTTPS)
SESSION_COOKIE_SECURE=true

# URL Scheme
PREFERRED_URL_SCHEME=https

# Trust proxy headers (nginx, cloudflare, etc.)
PROXY_FIX=true

# Flask debug mode (ALWAYS false in production)
FLASK_DEBUG=false

# -----------------------------------------------------------------------------
# DATABASE POOL (for high concurrency)
# -----------------------------------------------------------------------------
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=100

# -----------------------------------------------------------------------------
# CELERY WORKERS
# -----------------------------------------------------------------------------
SCRAPE_WORKERS=4
OPS_WORKERS=2
CELERY_CONCURRENCY=10

# -----------------------------------------------------------------------------
# SCRAPER SETTINGS
# -----------------------------------------------------------------------------
PLAYWRIGHT_FALLBACK=true
SCRAPER_LOG_LEVEL=INFO
DOMAIN_RATE_LIMIT=0.5
SCRAPER_BATCH_SIZE=500
PROXY_FAIL_THRESHOLD=10

# -----------------------------------------------------------------------------
# SERVER SETTINGS
# -----------------------------------------------------------------------------
HOST=0.0.0.0
PORT=5000
SERVER=waitress
WAITRESS_THREADS=8

# -----------------------------------------------------------------------------
# CI/CD DEPLOYMENT NOTES
# -----------------------------------------------------------------------------
# GitHub Actions Example:
#   - Store DATABASE_URL, REDIS_URL, SESSION_SECRET as repository secrets
#   - In workflow, set them as environment variables:
#     env:
#       DATABASE_URL: ${{ secrets.DATABASE_URL }}
#       REDIS_URL: ${{ secrets.REDIS_URL }}
#       SESSION_SECRET: ${{ secrets.SESSION_SECRET }}
#
# Docker Example:
#   docker run -e DATABASE_URL=... -e REDIS_URL=... -e SESSION_SECRET=... app
#
# The app reads from environment variables first, falls back to .env file
# -----------------------------------------------------------------------------
